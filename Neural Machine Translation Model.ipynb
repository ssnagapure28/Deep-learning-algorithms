{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English word tokens:  ['settled', 'ladies', 'szeged', 'insecure', 'caps', 'track', 'bounces', 'statistics', 'screw', 'rises', 'was', 'unpacked', 'overconfident', 'impressions', 'blond']\n",
      "Spanish word token::  ['bravura', 'cerrara', 'disparéis', 'parase', 'superaron', 'perspicaz', 'tréboles', 'obsesionado', 'mantuve', 'endulzante', 'esté', 'comienzo', 'equivalía', 'bisabuelo', 'quemaron']\n",
      "Word: ['go']\n",
      "Vector: [-0.83642954 -2.205397   -1.9177172  -2.7171035  -2.904938    1.1876247\n",
      "  0.9511666  -3.216733   -4.2320185   2.8309457   1.9119867   0.43954247\n",
      " -1.2282664   0.06773516  0.8859739  -1.240249   -1.1569941  -2.2372835\n",
      "  0.8699846   1.5118818   0.45527455  5.882317    1.5936309   1.9781195\n",
      " -0.42226812  1.7007952  -2.7771466   0.02887512  2.7459216  -1.652935\n",
      "  0.87697184  2.2297688  -0.14299941 -0.16993853 -1.2915593   0.3302774\n",
      " -1.2066706   1.7788837  -0.07550288  1.5663531  -1.8266319  -1.294214\n",
      " -0.60424817 -0.59220487 -2.3545537  -1.264424    2.3770056   3.328467\n",
      " -2.5673213  -0.4359831  -1.6154469   3.0063164   1.9640621   1.2822157\n",
      "  1.4076611  -2.52828     1.0065248  -2.8704922   1.443495   -0.8144089\n",
      "  1.5991249   1.1029925  -3.9320872   0.18878502  0.2912847   0.29364935\n",
      " -0.05240525 -2.4298115  -2.5474856   0.34478372  0.6539785  -0.5648392\n",
      " -0.9867213  -0.79590994 -1.9991089   2.1537223  -0.8361332   1.7481757\n",
      "  0.6235887  -1.7807665   1.8470044  -1.158636    0.46853808  1.5819646\n",
      "  2.9582112   1.097337   -1.6699746   1.4763534  -0.2759248   3.0757375\n",
      " -0.7207085  -0.09754214  1.7577051  -2.007399    0.36744294  1.4488873\n",
      " -0.31115636  1.0817162   1.9367552   1.2065276 ]\n",
      "\n",
      "Word: ['hi']\n",
      "Vector: [-0.83642954 -2.205397   -1.9177172  -2.7171035  -2.904938    1.1876247\n",
      "  0.9511666  -3.216733   -4.2320185   2.8309457   1.9119867   0.43954247\n",
      " -1.2282664   0.06773516  0.8859739  -1.240249   -1.1569941  -2.2372835\n",
      "  0.8699846   1.5118818   0.45527455  5.882317    1.5936309   1.9781195\n",
      " -0.42226812  1.7007952  -2.7771466   0.02887512  2.7459216  -1.652935\n",
      "  0.87697184  2.2297688  -0.14299941 -0.16993853 -1.2915593   0.3302774\n",
      " -1.2066706   1.7788837  -0.07550288  1.5663531  -1.8266319  -1.294214\n",
      " -0.60424817 -0.59220487 -2.3545537  -1.264424    2.3770056   3.328467\n",
      " -2.5673213  -0.4359831  -1.6154469   3.0063164   1.9640621   1.2822157\n",
      "  1.4076611  -2.52828     1.0065248  -2.8704922   1.443495   -0.8144089\n",
      "  1.5991249   1.1029925  -3.9320872   0.18878502  0.2912847   0.29364935\n",
      " -0.05240525 -2.4298115  -2.5474856   0.34478372  0.6539785  -0.5648392\n",
      " -0.9867213  -0.79590994 -1.9991089   2.1537223  -0.8361332   1.7481757\n",
      "  0.6235887  -1.7807665   1.8470044  -1.158636    0.46853808  1.5819646\n",
      "  2.9582112   1.097337   -1.6699746   1.4763534  -0.2759248   3.0757375\n",
      " -0.7207085  -0.09754214  1.7577051  -2.007399    0.36744294  1.4488873\n",
      " -0.31115636  1.0817162   1.9367552   1.2065276 ]\n",
      "\n",
      "Word: ['fire']\n",
      "Vector: [-0.83642954 -2.205397   -1.9177172  -2.7171035  -2.904938    1.1876247\n",
      "  0.9511666  -3.216733   -4.2320185   2.8309457   1.9119867   0.43954247\n",
      " -1.2282664   0.06773516  0.8859739  -1.240249   -1.1569941  -2.2372835\n",
      "  0.8699846   1.5118818   0.45527455  5.882317    1.5936309   1.9781195\n",
      " -0.42226812  1.7007952  -2.7771466   0.02887512  2.7459216  -1.652935\n",
      "  0.87697184  2.2297688  -0.14299941 -0.16993853 -1.2915593   0.3302774\n",
      " -1.2066706   1.7788837  -0.07550288  1.5663531  -1.8266319  -1.294214\n",
      " -0.60424817 -0.59220487 -2.3545537  -1.264424    2.3770056   3.328467\n",
      " -2.5673213  -0.4359831  -1.6154469   3.0063164   1.9640621   1.2822157\n",
      "  1.4076611  -2.52828     1.0065248  -2.8704922   1.443495   -0.8144089\n",
      "  1.5991249   1.1029925  -3.9320872   0.18878502  0.2912847   0.29364935\n",
      " -0.05240525 -2.4298115  -2.5474856   0.34478372  0.6539785  -0.5648392\n",
      " -0.9867213  -0.79590994 -1.9991089   2.1537223  -0.8361332   1.7481757\n",
      "  0.6235887  -1.7807665   1.8470044  -1.158636    0.46853808  1.5819646\n",
      "  2.9582112   1.097337   -1.6699746   1.4763534  -0.2759248   3.0757375\n",
      " -0.7207085  -0.09754214  1.7577051  -2.007399    0.36744294  1.4488873\n",
      " -0.31115636  1.0817162   1.9367552   1.2065276 ]\n",
      "\n",
      "Word: ['help']\n",
      "Vector: [-0.83642954 -2.205397   -1.9177172  -2.7171035  -2.904938    1.1876247\n",
      "  0.9511666  -3.216733   -4.2320185   2.8309457   1.9119867   0.43954247\n",
      " -1.2282664   0.06773516  0.8859739  -1.240249   -1.1569941  -2.2372835\n",
      "  0.8699846   1.5118818   0.45527455  5.882317    1.5936309   1.9781195\n",
      " -0.42226812  1.7007952  -2.7771466   0.02887512  2.7459216  -1.652935\n",
      "  0.87697184  2.2297688  -0.14299941 -0.16993853 -1.2915593   0.3302774\n",
      " -1.2066706   1.7788837  -0.07550288  1.5663531  -1.8266319  -1.294214\n",
      " -0.60424817 -0.59220487 -2.3545537  -1.264424    2.3770056   3.328467\n",
      " -2.5673213  -0.4359831  -1.6154469   3.0063164   1.9640621   1.2822157\n",
      "  1.4076611  -2.52828     1.0065248  -2.8704922   1.443495   -0.8144089\n",
      "  1.5991249   1.1029925  -3.9320872   0.18878502  0.2912847   0.29364935\n",
      " -0.05240525 -2.4298115  -2.5474856   0.34478372  0.6539785  -0.5648392\n",
      " -0.9867213  -0.79590994 -1.9991089   2.1537223  -0.8361332   1.7481757\n",
      "  0.6235887  -1.7807665   1.8470044  -1.158636    0.46853808  1.5819646\n",
      "  2.9582112   1.097337   -1.6699746   1.4763534  -0.2759248   3.0757375\n",
      " -0.7207085  -0.09754214  1.7577051  -2.007399    0.36744294  1.4488873\n",
      " -0.31115636  1.0817162   1.9367552   1.2065276 ]\n",
      "\n",
      "Word: ['stop']\n",
      "Vector: [-1.42988384e-01  3.55956435e-01 -3.92582834e-01  9.90761295e-02\n",
      "  2.23822594e-01  9.71323475e-02 -7.47378170e-01  3.75605881e-01\n",
      " -9.88074988e-02  8.19022596e-01 -5.64376354e-01  1.01874733e+00\n",
      " -1.46262228e-01  6.87398672e-01  4.06834483e-01 -3.90393212e-02\n",
      " -8.09273958e-01 -7.87662864e-02 -2.07158402e-01 -8.35196376e-01\n",
      "  2.21812725e-01 -1.40388072e-01 -7.48512983e-01  3.33676457e-01\n",
      " -1.04144490e+00  6.32534087e-01 -4.60782737e-01 -2.95433134e-01\n",
      " -5.30715048e-01 -6.34819327e-04  3.92434090e-01 -1.13192999e+00\n",
      " -4.77017850e-01 -4.06035244e-01  1.22383364e-01 -1.01907003e+00\n",
      "  3.29258442e-01 -5.81685185e-01 -6.23038173e-01  1.00728977e+00\n",
      "  2.85047650e-01 -3.42871882e-02 -3.65874320e-01 -7.31216371e-01\n",
      " -5.68076789e-01  1.90569088e-01 -4.95588928e-01  1.27210951e+00\n",
      "  2.78404832e-01 -9.08943594e-01  2.54443102e-02  4.78299111e-01\n",
      " -4.75700468e-01 -1.48252741e-01  4.73595709e-01  7.55711973e-01\n",
      "  1.89759463e-01  3.19264621e-01  2.44127735e-01 -3.09231192e-01\n",
      " -1.67156190e-01 -1.64906308e-01  1.51519388e-01 -1.84820265e-01\n",
      "  8.43847692e-02 -1.95369124e-01 -2.80791730e-01  8.59577119e-01\n",
      " -3.12599391e-01 -1.28274664e-01  5.69027126e-01  3.46157849e-01\n",
      "  8.65130648e-02  2.92835653e-01  9.99577902e-03  6.11673854e-03\n",
      "  1.50421947e-01 -3.41399580e-01 -9.37888101e-02  3.19630206e-01\n",
      "  3.54847074e-01 -1.14876106e-01  7.50333667e-01  2.13071898e-01\n",
      " -3.74749333e-01 -9.20512080e-01  1.08356690e+00 -1.12606995e-01\n",
      "  2.74681598e-01 -1.24668077e-01  6.91561639e-01 -2.15938941e-01\n",
      " -2.80741960e-01  3.32416087e-01 -1.82171300e-01 -1.29788667e-01\n",
      "  5.17583013e-01 -1.50788486e-01 -4.67889130e-01  2.35961676e-02]\n",
      "\n",
      "First 10 Spanish Word Vectors:\n",
      "Word: ['ve']\n",
      "Vector: [-1.39848793e+00  3.45192522e-01 -1.50266811e-01 -5.74071288e-01\n",
      "  1.23114836e+00 -1.20443511e+00  4.32853431e-01 -1.09522983e-01\n",
      " -7.74965733e-02 -5.51389635e-01 -2.33012176e+00  8.23652670e-02\n",
      "  1.41472054e+00 -1.02420092e+00  6.45382166e-01  8.71415496e-01\n",
      " -3.13647246e+00  1.15156226e-01  3.31619930e+00  6.23738170e-01\n",
      " -2.33498842e-01 -2.95449793e-01  5.14609814e-01  9.69062388e-01\n",
      "  3.49696726e-01 -1.88766706e+00 -1.15789533e+00  1.45490730e+00\n",
      "  9.89924252e-01  1.16225585e-01 -2.00220227e+00 -8.53745732e-03\n",
      "  6.81248009e-01  1.18059468e+00 -9.95141625e-01 -9.07945752e-01\n",
      "  8.06929708e-01  2.43716955e+00  2.17517757e+00 -4.03882593e-01\n",
      " -5.01395285e-01  4.56591398e-01  4.70672458e-01 -1.99370623e+00\n",
      "  4.83260661e-01  1.57950461e+00  5.31156063e-02 -6.80471957e-01\n",
      " -9.81898665e-01 -5.97311020e-01 -9.12340507e-02  5.30511796e-01\n",
      "  1.19420183e+00 -8.57264876e-01  3.19805169e+00 -6.86194777e-01\n",
      "  3.84450197e-01 -8.06639254e-01 -1.10274029e+00  1.03595436e+00\n",
      " -1.16924345e+00 -4.44753408e-01  2.40897346e+00 -3.70053202e-01\n",
      "  3.06776643e-01 -1.33937085e+00 -1.06345260e+00  1.61707211e+00\n",
      "  1.19118144e-04 -9.47618663e-01  1.55494571e+00 -1.63665581e+00\n",
      "  1.26040414e-01 -8.23532224e-01  1.10673398e-01 -1.46768391e+00\n",
      "  3.03158145e-02 -1.62668073e+00  7.15934299e-03 -9.21438158e-01\n",
      " -2.20824927e-01 -3.45643663e+00  2.45818377e+00  9.80327189e-01\n",
      "  1.73199320e+00  1.32308686e+00  1.03235996e+00  1.24022233e+00\n",
      " -1.68152893e+00 -2.61250663e+00 -1.35674819e-01  6.51018918e-01\n",
      "  1.32110178e+00  2.22579241e+00 -4.50255871e-02  9.63026583e-01\n",
      " -1.07759118e+00  7.75397956e-01 -1.60210764e+00 -1.58806705e+00]\n",
      "\n",
      "Word: ['hola']\n",
      "Vector: [ 0.9988908   0.6166459  -0.64477515  0.18979725  1.259616   -1.4933734\n",
      "  0.96337867 -0.6736838  -0.16844505 -0.7597802   0.30904633 -0.18245961\n",
      " -0.24571045  0.17167124  0.18646392 -0.8270926  -0.8354199   0.2443673\n",
      " -0.14969932 -0.69578063  1.2479526  -0.41727737 -0.23696621 -0.3165138\n",
      "  0.84617925 -0.06612282 -0.09642784 -0.33102643  0.04366584  1.6283576\n",
      "  0.8652333   0.75574666 -0.07089843 -0.97088265  0.45171395 -0.679341\n",
      " -1.1483554   0.8095088  -0.19758561 -0.02122289  0.8968478  -1.0500052\n",
      "  0.39719504 -0.08298257 -1.0012864   0.5618402  -1.0815365   1.2501346\n",
      "  0.6794905   0.0105362   0.9028427   0.06172224  0.82235616 -0.2465074\n",
      "  0.6246825  -0.15832458 -0.6026183  -0.460927   -0.20308872 -0.714981\n",
      " -0.04660727 -0.9797384   1.3054608  -0.13425532  1.3744485  -0.05420016\n",
      " -0.3415331   1.1266911  -0.25977516  1.1220758  -0.2513142  -1.3776459\n",
      "  0.4533062  -0.6157376   0.31704223 -0.768386    0.47766268 -0.95671815\n",
      "  1.0614674  -0.3138923   0.29135582 -1.8679703   1.3626081   0.89396906\n",
      "  0.7062168   0.3840375  -0.09101177 -0.14802802 -1.0492843  -0.9386328\n",
      "  0.01308093 -1.1813397   0.75117636  0.26051083 -0.09707256 -0.4454889\n",
      " -0.63037884 -0.15922418 -1.1888723   0.09389496]\n",
      "\n",
      "Word: ['fuego']\n",
      "Vector: [ 2.9882581  -1.4643842   1.887899   -0.8630678  -0.7234956  -0.16711402\n",
      "  1.6346819  -1.6973802  -1.3631893  -0.28162426 -0.7879944  -0.26555556\n",
      "  0.64445114 -2.8139343   1.4198502  -0.11088732 -1.6593592  -0.6974125\n",
      "  0.59453374 -1.0865238   0.62910795 -0.57266766 -1.1346873   0.37635556\n",
      "  0.67601514 -1.0382347  -1.3405452  -2.220275   -1.2816914  -0.7037523\n",
      "  0.34166476  1.230424    1.2620401   1.4482895   0.9174784  -0.19607228\n",
      "  0.51318365  0.3610551   0.3631185   0.9981404   0.43280584 -1.0021574\n",
      " -0.08918055 -0.49656114  0.23022182  0.8278226  -2.6001956  -0.5162489\n",
      "  0.57918423  1.5984697   0.6933031   0.61395615 -0.08322173 -2.6027293\n",
      " -0.06016903 -1.1652348   0.8304578  -3.0244865   0.7439809   0.94295883\n",
      " -0.9433773  -0.482915    1.3105972  -1.7074475   0.79954803 -1.1738856\n",
      " -1.1347531   0.99155986  0.3937345   0.41821608  1.124487   -0.41216528\n",
      " -1.1044255  -2.1149325  -1.9411801  -0.29153556 -0.45082113  0.50310755\n",
      "  2.0498545   0.6060452  -1.9538949  -2.3702714   0.55478966 -0.42579347\n",
      "  1.1482443  -0.5511534  -0.12209599 -0.8458691  -0.68705034 -3.3415308\n",
      " -1.5268201  -1.3526164   1.4302889   2.3558931  -0.8012093  -1.8181413\n",
      " -1.1949569   1.9821335  -1.8821934  -0.7960644 ]\n",
      "\n",
      "Word: ['socorro', 'auxilio']\n",
      "Vector: [ 0.3164922   0.25935552 -0.11763066 -0.14033832  0.12026084 -0.24513525\n",
      "  0.12323757 -0.06845466 -0.12993585 -0.30215064  0.12340399  0.16980065\n",
      "  0.00409209 -0.01466592 -0.00080072 -0.39276832  0.05113262  0.24128833\n",
      " -0.15028425 -0.39701107  0.6048356  -0.01183     0.3977264   0.09246683\n",
      "  0.31015566 -0.0223323  -0.10141858 -0.24556184  0.12556282  0.7419834\n",
      "  0.68303037  0.09688699  0.31470937 -0.146309    0.1672862  -0.13687594\n",
      " -0.5338128   0.35916254 -0.35277343 -0.24013735  0.15266354 -0.15702088\n",
      "  0.29891405  0.30258772  0.44692773  0.07697    -0.40530807  0.36730686\n",
      "  0.632132    0.08859643  0.44734776  0.15817869  0.51244736 -0.47527805\n",
      " -0.05186816  0.12183642  0.5168088   0.15733472 -0.13910025  0.03793703\n",
      " -0.17616516 -0.08333008  0.3040527   0.18681717 -0.3564475   0.60751194\n",
      " -0.1954701   0.16470154 -0.4929575   0.38282973  0.19786282 -0.21578711\n",
      " -0.04310325 -0.02568298  0.14800128 -0.14454924  0.01007929 -0.14438781\n",
      "  0.19142981 -0.29153287 -0.02181603 -0.3290605   0.65289307  0.5507127\n",
      " -0.13621123 -0.3449583   0.2866491   0.11244263 -0.12560332  0.06133147\n",
      "  0.3270362  -0.41196257  0.28797477  0.2703142  -0.09795882 -0.31842625\n",
      "  0.2577411   0.00576142 -0.1261714  -0.10505213]\n",
      "\n",
      "Word: ['parad']\n",
      "Vector: [-0.00207016  0.38227138  0.7337031   0.44461343 -0.3852742  -0.51116145\n",
      " -0.75362366  0.55541277  0.51609355 -1.2765684   1.5982629  -0.91046995\n",
      "  0.75828695 -0.69323885  1.140281   -0.15979765  0.67097217 -0.4582887\n",
      "  0.49681267 -0.19977088  0.11263824 -1.3436707  -0.1977847   0.22894397\n",
      "  0.1977717  -0.546964   -0.2983184   0.11871514 -0.41525686  0.17264389\n",
      " -0.14312649  0.0736234   0.18599047 -0.37926444  1.1522508  -1.35372\n",
      "  0.29629087  0.07385959  0.4533905   0.91321427  0.38409472 -0.27964732\n",
      "  0.18449408  0.50378454 -0.06232826  0.90020007  0.02671549 -0.16904342\n",
      "  0.02896971  0.61411387  0.6240047   0.8368242  -0.48960492 -0.85091126\n",
      " -0.4824496  -0.37409303 -0.7778257  -0.09188689 -0.4947554   0.61903864\n",
      " -0.53609306 -0.15542132  0.15965609 -0.01221798  0.43564144 -0.23981804\n",
      "  0.09208063  1.1326187   0.07456055 -0.11256894 -1.216823   -0.30759066\n",
      " -0.08893949 -0.52084076 -0.79078084  1.1721237  -0.41704857  0.93466103\n",
      "  0.56059754  0.631452   -0.7156027  -0.55391234 -0.70385414  0.24470969\n",
      " -0.04664081  0.51988035 -0.31349713 -0.45836863  0.877628    0.21444625\n",
      "  0.47874257  0.64381874 -0.54631037  0.185437   -0.8310457  -0.05061615\n",
      " -0.46250948  0.51554024 -0.86262155 -0.13583507]\n",
      "\n",
      "Word: ['esperen']\n",
      "Vector: [ 6.7996554e-02 -3.1157446e-01 -2.9456133e-01 -4.0447468e-01\n",
      "  9.2686588e-01 -1.1632402e+00  5.4597739e-02 -8.1007898e-02\n",
      " -4.8230800e-01 -1.2930305e+00 -1.3651457e-01  4.2563289e-01\n",
      "  3.2611343e-01 -1.1151052e+00  4.4112724e-01 -1.0910516e+00\n",
      " -4.7839969e-01 -6.0245252e-01 -2.4669857e-01 -4.0553111e-01\n",
      "  7.6497722e-01 -1.4164630e+00  9.7110905e-03 -8.9831752e-01\n",
      " -4.7321224e-01  1.7537375e-01 -1.1908787e+00 -2.0007741e-01\n",
      "  3.5134807e-01 -2.3752157e-01 -8.5233963e-01 -6.5844858e-01\n",
      "  9.4579555e-02  3.6831945e-01 -1.5541373e-01  8.4933752e-01\n",
      " -1.2333871e+00  4.6602431e-01  4.6005929e-01 -2.8233516e-01\n",
      " -7.5746638e-01  1.6319596e+00  8.1925236e-02 -4.3277293e-01\n",
      " -1.6062213e-01  1.5943724e+00  3.8766530e-01  1.6554247e-01\n",
      "  2.6604101e-01  2.8478119e-01 -6.1357081e-01 -8.1092513e-01\n",
      " -2.6243895e-01  4.5291600e-01  8.3417577e-01  8.6926872e-01\n",
      "  8.9740860e-01 -8.5566932e-01 -8.2968898e-02  4.3692672e-01\n",
      " -3.2249171e-01  1.6025443e-03  1.0225412e+00  3.2934587e-02\n",
      " -9.2860681e-01  4.0263519e-02 -9.3449831e-01  1.3994406e+00\n",
      "  4.9113142e-01  1.3112720e+00  8.5284978e-01  2.0442317e-01\n",
      "  4.3137193e-01  9.4178575e-01 -8.2838976e-01 -9.1519803e-01\n",
      " -3.5927001e-01 -3.7339857e-01  2.4352301e-02  2.4414827e-01\n",
      " -3.6003652e-01 -2.6344025e-01  4.1476950e-02  9.2798930e-01\n",
      "  6.7045546e-01 -5.2078116e-01 -2.7811232e-01 -3.0895412e-01\n",
      " -8.3533412e-01  1.9067805e-01 -2.7788770e-01 -2.9805160e-01\n",
      "  8.3746463e-01  1.3062664e+00 -3.2642075e-01 -9.4678265e-01\n",
      " -1.9996026e+00 -4.6907267e-01 -9.4991870e-02 -8.2023144e-01]\n",
      "\n",
      "Word: ['corrí']\n",
      "Vector: [ 4.7600712e-03  9.3933437e-03 -6.1838711e-03  3.9112722e-03\n",
      "  8.2278224e-03 -2.1226692e-03 -3.4799194e-03 -3.5879577e-03\n",
      " -6.1547663e-03 -8.6756777e-03 -5.1672827e-03 -1.1033261e-03\n",
      "  2.5413656e-03  4.0179514e-03 -2.7668965e-03 -8.6647347e-03\n",
      "  7.8559360e-03 -1.6979456e-03 -5.9971153e-03 -3.2655525e-03\n",
      "  5.1230406e-03  3.5730982e-03 -4.7768401e-03  1.8310189e-03\n",
      " -6.7913379e-03  6.2495554e-03  1.6507090e-03  7.8144076e-04\n",
      " -5.4652500e-03 -7.1528028e-03 -5.0894786e-03  5.6711244e-03\n",
      " -9.8598087e-03  8.7056757e-04  5.0272858e-03 -9.5360447e-03\n",
      "  8.9787720e-03 -8.6221732e-03 -6.3655032e-03  4.4168937e-03\n",
      " -5.6331159e-05  7.4288179e-03  3.3746194e-03 -1.1297476e-03\n",
      " -5.3185667e-03  8.1939828e-03  1.9008934e-03 -8.9950981e-03\n",
      "  7.4880910e-03  2.0189916e-03  3.5720670e-03 -5.5606281e-03\n",
      " -2.5202704e-03 -1.7595279e-03  7.2572054e-03 -1.6891039e-03\n",
      "  9.1204206e-03 -1.4730692e-05  7.4342894e-03 -3.8695515e-03\n",
      " -7.3378085e-04 -1.8054604e-03  7.7432645e-03  1.4150750e-03\n",
      "  7.2639897e-03  4.3549514e-03  3.0718779e-03  2.0911836e-03\n",
      "  3.6170506e-03 -4.2144512e-03  1.3828826e-03  1.0167802e-03\n",
      " -5.7058083e-03  4.6744347e-03  3.9107432e-03  5.2822148e-03\n",
      "  4.5659901e-03  3.5869693e-03  3.8431347e-03  1.4193022e-03\n",
      " -2.9127873e-03 -5.5879261e-03  5.7686568e-05  6.7328527e-03\n",
      " -4.3246327e-03  4.4161439e-04 -2.7265514e-03 -9.0668872e-03\n",
      " -6.1908341e-03 -4.8421384e-03 -1.8284285e-03 -7.4764909e-03\n",
      " -6.9609750e-03 -7.1706536e-04 -2.3549164e-03 -7.9701431e-03\n",
      " -5.5596218e-03  5.9698131e-03  8.7727665e-04  4.3979036e-03]\n",
      "\n",
      "Word: ['oh', 'no']\n",
      "Vector: [ 0.03339578  1.9248829  -0.2911259   1.5171199  -0.5626474   0.5686146\n",
      "  0.64229    -0.7715514   1.0571764   1.6390306  -3.2439353  -1.1741326\n",
      " -0.30138662 -1.4148369  -2.3259645  -0.8744399   0.26415142 -0.56945884\n",
      "  0.31221327 -3.365137    1.7229245   1.1634121   0.21913104  0.0253049\n",
      " -1.614709    2.2206094   1.5166184   3.2127004   0.14617364  0.7996981\n",
      "  0.6826766  -1.9517446  -0.45807138 -1.5639929   0.5335666  -0.6006488\n",
      " -1.3862164  -1.1329703  -0.1662813   0.5815615   0.37077785  0.73737466\n",
      " -0.22380498 -0.65404105  0.21695268 -2.4667256  -1.5780172   0.48930472\n",
      " -2.092894   -0.11619075  2.5887535   0.14441606  2.1750169  -1.303305\n",
      " -1.7035621  -1.797876   -0.83904356  1.4643642  -0.3064296  -2.178604\n",
      "  2.1685514   0.71659505  0.72414    -0.52807677 -1.3752695   0.84783226\n",
      "  1.9881221   1.37573     2.4187853  -0.5320153  -3.199215    0.8409761\n",
      " -0.47553584 -0.79176104 -1.0075482   1.0212091  -0.9963233   4.25193\n",
      " -0.66668516  3.7115128  -0.31010848  2.1284068   1.9435871  -1.3555981\n",
      " -1.8315634   4.084965    1.6999947  -2.4965882   2.6055088  -0.15269992\n",
      " -1.1739619  -1.2136852  -1.8221773   0.44328824 -2.8506284   1.925466\n",
      " -2.4609609   3.7890756   0.05972     1.6274712 ]\n",
      "\n",
      "Word: ['atacad']\n",
      "Vector: [-0.31441903  0.33129     0.55013585 -0.05129881  1.0161457  -1.5199008\n",
      " -2.3435252  -1.7838438  -0.06000865 -0.9009603  -2.8406315   0.08868951\n",
      " -0.61372626  0.33526534 -0.7658999  -1.5247147  -0.896241    1.9549874\n",
      "  2.1411476  -1.1453015  -0.49555704 -0.05493956 -0.52967364 -0.34308034\n",
      " -2.0427408   0.8869334   0.06131652  1.3952391   1.0794837   2.3056977\n",
      "  1.848036   -0.41578752  1.6573225  -1.6164794   0.573676   -0.631925\n",
      " -1.1261811   0.01226826 -1.6190503   1.3388822  -1.4508041  -0.24434035\n",
      " -0.69674134 -0.6841663  -0.9369037   0.4476853  -0.5878785  -0.63501483\n",
      "  0.56822795 -0.23012626  1.629167   -0.21092457 -1.7346005  -1.26163\n",
      "  2.1260242   1.4671842  -0.9595402  -1.0228952  -0.21614711 -2.810679\n",
      "  0.2150722  -0.06770326  0.4469842  -0.63657403  0.00355389 -0.35532707\n",
      " -1.5837189   0.84025156  2.132251    0.15433955 -1.3189135   0.87500876\n",
      "  1.8050487   1.4408743   0.09784868  1.0600337  -1.2716445  -1.4574231\n",
      " -1.8087862  -0.34270146  1.0073924   1.3764486  -0.5014045   1.3436244\n",
      "  1.4405324  -0.09118536 -1.9852833  -1.2472998  -0.57935584 -1.5949953\n",
      "  1.4837255   0.51424325  0.836996   -0.03558574 -1.7627418  -0.13241091\n",
      " -1.4132457   0.2813676  -1.0106618   1.2161458 ]\n",
      "\n",
      "Word: ['lo', 'pillas']\n",
      "Vector: [-0.21109621  1.7720132   0.74664736  0.08797766 -0.11584576  0.0827001\n",
      " -1.3192317   0.39515758 -0.33278555 -0.10676751 -0.8649872  -0.3562298\n",
      "  1.9339906  -0.33900857 -1.9192017   0.30207428 -1.6440511  -0.31743607\n",
      "  1.7335888  -1.0334368  -1.0608339  -0.06283971  0.3620946  -0.2194147\n",
      "  0.4123946  -1.0315372   1.2713165   0.49475893 -0.5529816   2.6328568\n",
      "  3.237789   -0.8002728   1.7075156  -0.01300139 -0.66439867 -0.49097398\n",
      " -1.016821    0.79768527 -1.3832623   0.9400885   0.35846776  1.0215346\n",
      " -0.5881788  -0.52138746 -0.7080082   0.20403998  1.414587   -0.70358694\n",
      " -0.77646947 -0.0767253   0.62439764  0.7743892  -0.6057649   0.3123817\n",
      "  0.4822975   1.1990757   0.47090447  0.01431527  1.4554206  -1.0822648\n",
      "  0.39813918  1.3911419   0.09733616 -0.06415188 -0.7156165   1.0858085\n",
      " -1.8030647   0.20443657  1.5493876  -0.33540207  1.5517838  -0.40765753\n",
      "  2.3722124   0.08063257  0.37087882  1.6197985   0.86491096 -1.306892\n",
      " -0.7366651   0.02559538  0.92940617  0.8339042  -2.5169194   0.56761205\n",
      "  1.5008181  -0.3715942   0.22144832 -0.958034    0.51725215  1.0068502\n",
      "  0.8926191   0.97503614 -0.9196952  -0.91579944 -0.85130364  0.36832145\n",
      "  0.73890066  0.6707478   1.7979844  -0.0335244 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import pathlib\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.data as tf_data\n",
    "import tensorflow.strings as tf_strings\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "from keras.layers import TextVectorization\n",
    "import string\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "text_file = keras.utils.get_file(\n",
    "    fname=\"spa-eng.zip\",\n",
    "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
    "    extract=True,\n",
    ")\n",
    "text_file = pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\"\n",
    "\n",
    "\n",
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "english_words = []\n",
    "spanish_words = []\n",
    "\n",
    "def remove_punctuation(sentence):\n",
    "    return sentence.translate(str.maketrans('', '', string.punctuation + '¿¡' ))\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    return remove_punctuation(sentence).lower()\n",
    "\n",
    "for line in lines:\n",
    "    eng, spa = line.split(\"\\t\")\n",
    "    english_words.append(preprocess_sentence(eng))\n",
    "    spanish_words.append(preprocess_sentence(spa))\n",
    "\n",
    "def preprocess_data(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text.lower().split()\n",
    "\n",
    "\n",
    "embedding_dimension = 100\n",
    "\n",
    "english_words = [preprocess_data(word) for word in english_words]\n",
    "spanish_words = [preprocess_data(pair) for pair in spanish_words]\n",
    "# Flatten the lists of tokens\n",
    "english_tokens = [token for sentence in english_words for token in sentence]\n",
    "spanish_tokens = [token for sentence in spanish_words for token in sentence]\n",
    "\n",
    "print('English word tokens: ', (list(set(english_tokens)))[:15])\n",
    "print('Spanish word token:: ',  (list(set(spanish_tokens)))[:15])\n",
    "\n",
    "english_cbow_model = Word2Vec(sentences=english_words, vector_size=embedding_dimension, window=5, sg=0, min_count=1, epochs=50)\n",
    "spanish_cbow_model = Word2Vec(sentences=spanish_words, vector_size=embedding_dimension, window=5, sg=0, min_count=1, epochs=50)\n",
    "\n",
    "def map_words_to_vectors(sentences, cbow_model):\n",
    "    vectors = []\n",
    "    for sentence in sentences:\n",
    "        vector = np.mean([cbow_model.wv[word] for word in sentence if word in cbow_model.wv], axis=0)\n",
    "        vectors.append(vector)\n",
    "    return vectors\n",
    "\n",
    "english_vectors = map_words_to_vectors(english_words, english_cbow_model)\n",
    "spanish_vectors = map_words_to_vectors(spanish_words, spanish_cbow_model)\n",
    "\n",
    "# print(\"English Word to Index Dictionary:\", english_word_to_index)\n",
    "# print(\"Spanish Word to Index Dictionary:\", spanish_word_to_index)\n",
    " \n",
    "for i in range(5):\n",
    "    print(\"Word:\", english_words[i*4])\n",
    "    print(\"Vector:\", english_vectors[i])\n",
    "    print()\n",
    "print(\"First 10 Spanish Word Vectors:\")\n",
    "for i in range(10):\n",
    "    print(\"Word:\", spanish_words[i*4])\n",
    "    print(\"Vector:\", spanish_vectors[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total english tokens:  26025\n",
      "Spanish vocab size:  26025\n",
      "Max sequence length for English: 47\n",
      "Max sequence length for Spanish: 49\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "max_eng_seq_length = max(len(sentence) for sentence in english_words)\n",
    "max_spa_seq_length = max(len(sentence) for sentence in spanish_words)\n",
    "english_vocab_size = len(set(english_tokens))\n",
    "spanish_vocab_size = len(set(spanish_tokens))\n",
    "print('Total english tokens: ', len(set(spanish_tokens)))\n",
    "print('Spanish vocab size: ', spanish_vocab_size)\n",
    "print(\"Max sequence length for English:\", max_eng_seq_length)\n",
    "print(\"Max sequence length for Spanish:\", max_spa_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar words to girl in English: [('boy', 0.7343618273735046), ('woman', 0.6738501191139221), ('man', 0.5900071263313293), ('doll', 0.5262684226036072), ('child', 0.5247960686683655)]\n",
      "Similar words to dress in English: [('skirt', 0.6811878681182861), ('sweater', 0.677156388759613), ('hat', 0.6525558829307556), ('shirt', 0.6519303917884827), ('jacket', 0.6336907744407654)]\n",
      "Similar words to test in English: [('exam', 0.6777861714363098), ('examination', 0.618669331073761), ('subject', 0.45732221007347107), ('student', 0.4531395733356476), ('picnic', 0.449260413646698)]\n",
      "Similar words to walk in English: [('swim', 0.5474985241889954), ('drive', 0.5462285876274109), ('run', 0.5331001281738281), ('taxi', 0.5215353965759277), ('shower', 0.5137079358100891)]\n",
      "Similar words to food in English: [('fruit', 0.570177435874939), ('rice', 0.5175455212593079), ('vegetables', 0.5147916078567505), ('sushi', 0.5082530975341797), ('wine', 0.49756258726119995)]\n",
      "-----------------------------------------------------------\n",
      "Similar words to bien in English: [('mal', 0.5079329013824463), ('cargado', 0.43716269731521606), ('ocupado', 0.43595239520072937), ('maravilla', 0.4291418492794037), ('futurista', 0.42298150062561035)]\n",
      "Similar words to hola in English: [('exactamente', 0.4703194200992584), ('denante', 0.425911009311676), ('adiós', 0.4208456873893738), ('boludeces', 0.40011197328567505), ('bromeando', 0.39706775546073914)]\n",
      "Similar words to marineros in English: [('obreros', 0.7636166214942932), ('testigos', 0.7523024678230286), ('desiertos', 0.7435743808746338), ('granjeros', 0.7429073452949524), ('chiquillos', 0.7364949584007263)]\n",
      "Similar words to alimento in English: [('alimentaba', 0.5298599004745483), ('entrené', 0.5016071200370789), ('amarré', 0.501189112663269), ('alimenta', 0.49283990263938904), ('até', 0.4876343309879303)]\n",
      "Similar words to ropa in English: [('chaqueta', 0.6521886587142944), ('pieza', 0.6133170127868652), ('camisa', 0.610837459564209), ('alfombra', 0.5804389119148254), ('mochila', 0.5781643986701965)]\n"
     ]
    }
   ],
   "source": [
    "target_words = [\"girl\", \"dress\", \"test\", \"walk\", \"food\"]\n",
    "\n",
    "for target_word in target_words:\n",
    "    similar_words_english = english_cbow_model.wv.most_similar(target_word, topn=5)\n",
    "    print(f\"Similar words to {target_word} in English:\", similar_words_english)\n",
    "print('-----------------------------------------------------------')\n",
    "target_words = [\"bien\", \"hola\", \"marineros\", \"alimento\", \"ropa\"]\n",
    "for target_word in target_words:\n",
    "    similar_words_spanish = spanish_cbow_model.wv.most_similar(target_word, topn=5)\n",
    "    print(f\"Similar words to {target_word} in English:\", similar_words_spanish)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m  22/2343\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:30:13\u001b[0m 2s/step - loss: 0.3643"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Attention, Concatenate\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "\n",
    "# Reshape the input data to include a third dimension\n",
    "english_vectors_np = np.expand_dims(english_vectors, axis=-1)\n",
    "spanish_vectors_np = np.expand_dims(spanish_vectors, axis=-1)\n",
    "# Split the data into train and test sets\n",
    "english_train, english_test, spanish_train, spanish_test = train_test_split(english_vectors_np, spanish_vectors_np, test_size=0.3)\n",
    "latent_dim = 256\n",
    "\n",
    "encoder_inputs = Input(shape=(100, 1))\n",
    "\n",
    "# Encoder Layer\n",
    "encoder_lstm1 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "encoder_outputs1, state_h1, state_c1 = encoder_lstm1(encoder_inputs)\n",
    "\n",
    "encoder_lstm2 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm2(encoder_outputs1)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Decoder Input\n",
    "decoder_inputs = Input(shape=(100, 1))\n",
    "\n",
    "# Decoder Layer\n",
    "decoder_lstm1 = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs1, _, _ = decoder_lstm1(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "# Attention \n",
    "attention_layer = Attention()\n",
    "attention_out = attention_layer([decoder_outputs1, encoder_outputs])\n",
    "decoder_concat_input = Concatenate(axis=-1)([decoder_outputs1, attention_out])\n",
    "\n",
    "# Output Layer\n",
    "decoder_dense = Dense(spanish_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "optimizer = RMSprop(learning_rate=0.1)\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "model.fit([english_train, spanish_train], spanish_train,\n",
    "          batch_size=32,\n",
    "          epochs=30,\n",
    "          validation_split=0.1)\n",
    "\n",
    "# loss = model.evaluate([english_test, spanish_test], spanish_test)\n",
    "# print(\"Test loss:\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
